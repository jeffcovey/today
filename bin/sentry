#!/usr/bin/env ruby

# frozen_string_literal: true

# If .env is encrypted and we're not already running under dotenvx, re-exec with dotenvx
if ENV['DOTENV_PRIVATE_KEY'].nil? &&
   File.exist?('.env') &&
   File.exist?('.env.keys') &&
   File.read('.env', 100).include?('DOTENV_PUBLIC_KEY')

  # Extract private key from .env.keys
  private_key = File.readlines('.env.keys').find { |line| line.start_with?('DOTENV_PRIVATE_KEY=') }
  if private_key && system('which npx > /dev/null 2>&1')
    ENV['DOTENV_PRIVATE_KEY'] = private_key.strip.split('=', 2)[1]
    exec('npx', 'dotenvx', 'run', '--', 'ruby', __FILE__, *ARGV)
  end
end

require "net/http"
require "json"
require "uri"
require "fileutils"
require "time"

class SentryClient
  API_BASE = "https://sentry.io/api/0"
  ARCHIVE_DIR = "plans/archived-data/sentry"

  def initialize(auth_token = nil)
    @auth_token = auth_token || ENV.fetch("SENTRY_AUTH_TOKEN", nil)
    @organization = ENV.fetch("SENTRY_ORG")
    @project = ENV.fetch("SENTRY_PROJECT", "rails")

    if @auth_token.nil? || @auth_token.empty?
      puts "Error: No Sentry authentication token found."
      puts "Please set the SENTRY_AUTH_TOKEN environment variable."
      puts "You can create an auth token at: https://sentry.io/settings/account/api/auth-tokens/"
      puts "The token needs at least 'project:read' and 'event:read' scopes."
      exit 1
    end

    FileUtils.mkdir_p(ARCHIVE_DIR)
  end

  # Fetch a single issue by ID
  def fetch_issue(issue_id)
    uri = URI("#{API_BASE}/issues/#{issue_id}/")
    make_request(uri)
  end

  # Fetch events for an issue
  def fetch_issue_events(issue_id, limit = 10)
    uri = URI("#{API_BASE}/issues/#{issue_id}/events/?limit=#{limit}")
    make_request(uri)
  end

  # List recent issues for the project
  def list_recent_issues(limit = 25, resolved = nil, query = nil)
    params = ["limit=#{limit}"]
    params << "query=is:#{resolved ? 'resolved' : 'unresolved'}" if !resolved.nil?
    params << "query=#{URI.encode_www_form_component(query)}" if query && resolved.nil?

    uri = URI("#{API_BASE}/projects/#{@organization}/#{@project}/issues/?#{params.join('&')}")
    make_request(uri)
  end

  # List all issues with pagination
  def list_all_issues(cursor = nil, limit = 100)
    params = ["limit=#{limit}"]
    params << "cursor=#{cursor}" if cursor

    uri = URI("#{API_BASE}/projects/#{@organization}/#{@project}/issues/?#{params.join('&')}")
    make_request(uri)
  end

  # Archive a single issue
  def archive_issue(issue_id)
    issue_data = fetch_issue(issue_id)
    return issue_data if issue_data.is_a?(Hash) && issue_data[:error]

    # Add events data
    events = fetch_issue_events(issue_id, 5)
    issue_data[:events] = events unless events.is_a?(Hash) && events[:error]

    file_path = File.join(ARCHIVE_DIR, "issue-#{issue_id}.json")
    File.write(file_path, JSON.pretty_generate(issue_data))
    puts "✓ Archived issue #{issue_id}"
    issue_data
  end

  # Archive all issues
  def archive_all_issues(filter = nil, recent_only = true)
    puts "Archiving Sentry issues..."

    # For recent_only, limit to 100 most recent issues
    # Otherwise, paginate through all
    limit = recent_only ? 100 : 100
    cursor = nil
    all_issues = []
    page = 0
    max_pages = recent_only ? 1 : 10 # Limit pages for safety

    loop do
      page += 1
      puts "Fetching page #{page}..."

      result = list_all_issues(cursor, limit)

      if result.is_a?(Hash) && result[:error]
        puts "Error fetching issues: #{result[:error]}"
        break
      end

      issues = result
      break if issues.nil? || issues.empty?

      issues.each do |issue|
        # Apply filter if specified
        if filter == "resolved" && issue["status"] != "resolved"
          next
        elsif filter == "unresolved" && issue["status"] == "resolved"
          next
        end

        all_issues << issue

        # Archive individual issue with full details
        issue_id = issue["id"]
        file_path = File.join(ARCHIVE_DIR, "issue-#{issue_id}.json")

        # Fetch full issue details if not already archived
        if !File.exist?(file_path) || !recent_only
          full_issue = fetch_issue(issue_id)
          unless full_issue.is_a?(Hash) && full_issue[:error]
            # Add minimal event data
            events = fetch_issue_events(issue_id, 3)
            full_issue[:events] = events unless events.is_a?(Hash) && events[:error]

            File.write(file_path, JSON.pretty_generate(full_issue))
            puts "  ✓ Archived issue #{issue_id}: #{issue['title'][0..50]}"
          end
        else
          puts "  → Skipping existing issue #{issue_id}"
        end
      end

      # Check if we have more pages
      break if recent_only || page >= max_pages

      # Sentry uses Link header for pagination
      # For simplicity, we'll stop after max_pages
      sleep 0.5 # Rate limiting
    end

    # Update master index
    update_master_index(all_issues)

    puts "✓ Archived #{all_issues.length} issues"
    all_issues
  end

  private

  def make_request(uri)
    request = Net::HTTP::Get.new(uri)
    request["Authorization"] = "Bearer #{@auth_token}"
    request["Content-Type"] = "application/json"

    response = Net::HTTP.start(uri.hostname, uri.port, use_ssl: true) do |http|
      http.request(request)
    end

    case response.code.to_i
    when 200..299
      JSON.parse(response.body)
    when 401
      { error: "Authentication failed. Check your SENTRY_AUTH_TOKEN." }
    when 404
      { error: "Not found" }
    else
      { error: "Request failed: #{response.code} #{response.message}" }
    end
  rescue JSON::ParserError => e
    { error: "Failed to parse response: #{e.message}" }
  rescue => e
    { error: "Request error: #{e.message}" }
  end

  def update_master_index(issues)
    master_index_path = File.join("plans/archived-data", "master-index.json")

    index = if File.exist?(master_index_path)
      JSON.parse(File.read(master_index_path))
    else
      { "created_at" => Time.now.iso8601 }
    end

    index["updated_at"] = Time.now.iso8601
    index["sentry_issues"] = issues.map do |issue|
      {
        "id" => issue["id"],
        "title" => issue["title"],
        "status" => issue["status"],
        "level" => issue["level"],
        "culprit" => issue["culprit"],
        "count" => issue["count"],
        "userCount" => issue["userCount"],
        "firstSeen" => issue["firstSeen"],
        "lastSeen" => issue["lastSeen"],
        "archived_at" => Time.now.iso8601
      }
    end

    File.write(master_index_path, JSON.pretty_generate(index))
    puts "✓ Updated master index with #{issues.length} Sentry issues"
  end
end

# CLI Interface
def main
  if ARGV.empty?
    puts "Usage: #{$0} <command> [options]"
    puts ""
    puts "Commands:"
    puts "  list [limit]             - List recent issues"
    puts "  list-resolved [limit]    - List resolved issues"
    puts "  list-unresolved [limit]  - List unresolved issues"
    puts "  search <query> [limit]   - Search issues"
    puts "  show <issue_id>          - Show issue details"
    puts "  events <issue_id> [limit] - Show issue events"
    puts "  archive <issue_id>       - Archive a single issue"
    puts "  archive-all [filter] [recent] - Archive all issues"
    puts "                           filter: all|resolved|unresolved"
    puts "                           recent: recent|all (default: recent)"
    puts ""
    puts "Examples:"
    puts "  #{$0} list 10"
    puts "  #{$0} list-unresolved 25"
    puts "  #{$0} search 'error level:error' 20"
    puts "  #{$0} show 123456789"
    puts "  #{$0} archive 123456789"
    puts "  #{$0} archive-all unresolved recent"
    exit 1
  end

  client = SentryClient.new
  command = ARGV[0]

  case command
  when "list"
    limit = (ARGV[1] || 25).to_i
    result = client.list_recent_issues(limit)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    else
      result.each do |issue|
        status = issue["status"] == "resolved" ? "✓" : "✗"
        puts "[#{status}] #{issue['id']}: #{issue['title'][0..80]}"
        puts "  Level: #{issue['level']}, Count: #{issue['count']}, Users: #{issue['userCount']}"
        puts "  Last seen: #{issue['lastSeen']}"
        puts ""
      end
    end

  when "list-resolved"
    limit = (ARGV[1] || 25).to_i
    result = client.list_recent_issues(limit, true)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    else
      result.each do |issue|
        puts "[✓] #{issue['id']}: #{issue['title'][0..80]}"
        puts "  Count: #{issue['count']}, Last seen: #{issue['lastSeen']}"
        puts ""
      end
    end

  when "list-unresolved"
    limit = (ARGV[1] || 25).to_i
    result = client.list_recent_issues(limit, false)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    else
      result.each do |issue|
        puts "[✗] #{issue['id']}: #{issue['title'][0..80]}"
        puts "  Level: #{issue['level']}, Count: #{issue['count']}, Users: #{issue['userCount']}"
        puts "  Last seen: #{issue['lastSeen']}"
        puts ""
      end
    end

  when "search"
    query = ARGV[1]
    limit = (ARGV[2] || 25).to_i
    unless query
      puts "Error: Search query required"
      exit 1
    end
    result = client.list_recent_issues(limit, nil, query)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    else
      result.each do |issue|
        status = issue["status"] == "resolved" ? "✓" : "✗"
        puts "[#{status}] #{issue['id']}: #{issue['title'][0..80]}"
        puts "  Count: #{issue['count']}, Last seen: #{issue['lastSeen']}"
        puts ""
      end
    end

  when "show"
    issue_id = ARGV[1]
    unless issue_id
      puts "Error: Issue ID required"
      exit 1
    end
    result = client.fetch_issue(issue_id)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    else
      puts JSON.pretty_generate(result)
    end

  when "events"
    issue_id = ARGV[1]
    limit = (ARGV[2] || 10).to_i
    unless issue_id
      puts "Error: Issue ID required"
      exit 1
    end
    result = client.fetch_issue_events(issue_id, limit)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    else
      result.each_with_index do |event, i|
        puts "Event #{i + 1}:"
        puts "  ID: #{event['id']}"
        puts "  Date: #{event['dateCreated']}"
        puts "  Message: #{event['message']}" if event['message']
        puts ""
      end
    end

  when "archive"
    issue_id = ARGV[1]
    unless issue_id
      puts "Error: Issue ID required"
      exit 1
    end
    result = client.archive_issue(issue_id)
    if result.is_a?(Hash) && result[:error]
      puts "Error: #{result[:error]}"
    end

  when "archive-all"
    filter = ARGV[1] || "unresolved"
    recent = ARGV[2] != "all"

    unless %w[all resolved unresolved].include?(filter)
      puts "Error: Invalid filter. Use 'all', 'resolved', or 'unresolved'"
      exit 1
    end

    filter_param = filter == "all" ? nil : filter
    client.archive_all_issues(filter_param, recent)

  else
    puts "Unknown command: #{command}"
    exit 1
  end
end

main if __FILE__ == $0