#!/usr/bin/env python3
"""
Today - Daily review and planning tool

Usage:
    bin/today [options] [command] [request]
    bin/today update                  # Update review file via API
    bin/today --no-sync               # Skip sync step
    bin/today "specific request"      # Focused session with request
"""

import os
import sys
import subprocess
import argparse
from datetime import datetime, timedelta
from pathlib import Path
import json
import re
import sqlite3
from collections import defaultdict
import glob
import zipfile

# Add src directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

def load_dotenv():
    """Load encrypted environment variables using dotenvx"""
    try:
        # Check if we have encrypted env
        if Path('.env').exists():
            result = subprocess.run(
                ['npx', 'dotenvx', 'get', 'TODAY_ANTHROPIC_KEY'],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                os.environ['TODAY_ANTHROPIC_KEY'] = result.stdout.strip()
    except Exception:
        pass  # Continue without the key

def get_review_file_path():
    """Calculate the current review file path"""
    now = datetime.now()
    year = now.year
    month = now.month
    day = now.day
    week = now.isocalendar()[1]

    # Determine quarter
    quarter = f"Q{(month - 1) // 3 + 1}"

    return f"vault/plans/{year}_{quarter}_{month:02d}_W{week:02d}_{day:02d}.md"

def get_stage_info():
    """Get current stage theme and focus"""
    day_of_week = datetime.now().strftime('%A')

    stages = {
        'Monday': ('Front Stage', 'Meetings, calls, support, emails'),
        'Wednesday': ('Front Stage', 'Meetings, calls, support, emails'),
        'Saturday': ('Front Stage', 'Meetings, calls, support, emails'),
        'Thursday': ('Back Stage', 'Maintenance, bills, bug fixes, organizing'),
        'Sunday': ('Back Stage', 'Maintenance, bills, bug fixes, organizing'),
        'Tuesday': ('Off Stage', 'Personal time, nature, friends, reading'),
        'Friday': ('Off Stage', 'Personal time, nature, friends, reading'),
    }

    return stages.get(day_of_week, ('Unknown', 'Unknown'))

def get_task_statistics():
    """Get task statistics from markdown files"""
    stats = {'total': 0, 'overdue': 0, 'high_priority': 0}
    today = datetime.now().date()

    # Find all markdown files
    md_files = []
    for pattern in ['vault/**/*.md', 'vault/*.md']:
        md_files.extend(glob.glob(pattern, recursive=True))

    # Exclude templates
    md_files = [f for f in md_files if '/templates/' not in f and '/.sync/' not in f]

    for file_path in md_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

                # Count unchecked tasks
                tasks = re.findall(r'^- \[ \].*$', content, re.MULTILINE)
                stats['total'] += len(tasks)

                # Count overdue (with üìÖ or ‚è≥ dates before today)
                for task in tasks:
                    # Check for high priority
                    if 'üî∫' in task or '‚è´' in task or 'üî¥' in task:
                        stats['high_priority'] += 1

                    # Check for dates
                    date_match = re.search(r'[üìÖ‚è≥]\s*(\d{4}-\d{2}-\d{2})', task)
                    if date_match:
                        task_date = datetime.strptime(date_match.group(1), '%Y-%m-%d').date()
                        if task_date < today:
                            stats['overdue'] += 1
        except Exception:
            continue

    return stats

def get_health_metrics():
    """Extract health metrics from Apple Health export"""
    # Look for the most recent health export file (either .zip or .json with date range)
    health_files = glob.glob('vault/logs/HealthAutoExport*.json') + glob.glob('vault/logs/HealthAutoExport*.zip')

    if not health_files:
        return ""

    # Sort by modification time to get the most recent
    health_files.sort(key=lambda x: Path(x).stat().st_mtime, reverse=True)
    health_export = health_files[0]

    try:
        # Check if it's a JSON file directly
        if health_export.endswith('.json'):
            with open(health_export, 'r') as f:
                data = json.load(f)
        else:
            # It's a zip file, extract and analyze
            with zipfile.ZipFile(health_export, 'r') as z:
                # Find the JSON file
                json_files = [f for f in z.namelist() if f.startswith('HealthAutoExport') and f.endswith('.json')]
                if not json_files:
                    return ""

                with z.open(json_files[0]) as f:
                    data = json.load(f)

                # Process metrics
                yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
                metrics = {}

                for metric in data.get('data', {}).get('metrics', []):
                    if metric.get('name') == 'step_count':
                        daily_steps = defaultdict(float)
                        for entry in metric.get('data', []):
                            date_str = entry['date'].split()[0]
                            steps = entry.get('qty', 0)
                            daily_steps[date_str] += steps

                        # Last 7 days average
                        recent_dates = sorted(daily_steps.keys())[-7:]
                        if recent_dates:
                            avg_steps = sum(daily_steps[d] for d in recent_dates) / len(recent_dates)
                            metrics['avg_steps'] = int(avg_steps)
                            if yesterday in daily_steps:
                                metrics['yesterday_steps'] = int(daily_steps[yesterday])

                    elif metric.get('name') == 'weight_body_mass':
                        weights = [(e['date'].split()[0], e.get('qty', 0))
                                 for e in metric.get('data', [])]
                        if weights:
                            weights.sort()
                            metrics['weight'] = f"{weights[-1][1]:.1f} lbs"

                # Format as string
                if metrics:
                    lines = ["\n## Health Metrics (Last 7 days)"]
                    if 'avg_steps' in metrics:
                        lines.append(f"- **Average Steps**: {metrics['avg_steps']}/day")
                    if 'yesterday_steps' in metrics:
                        lines.append(f"- **Yesterday**: {metrics['yesterday_steps']} steps")
                    if 'weight' in metrics:
                        lines.append(f"- **Weight**: {metrics['weight']}")
                    return '\n'.join(lines)
    except Exception:
        pass

    return ""

def get_existing_plans():
    """Check which planning files exist"""
    now = datetime.now()
    year = now.year
    month = now.month
    week = now.isocalendar()[1]
    quarter = f"Q{(month - 1) // 3 + 1}"

    plans = []
    plan_files = [
        (f"vault/plans/{year}_00.md", "Year plan"),
        (f"vault/plans/{year}_{quarter}_00.md", "Quarter plan"),
        (f"vault/plans/{year}_{quarter}_{month:02d}_00.md", "Month plan"),
        (f"vault/plans/{year}_{quarter}_{month:02d}_W{week:02d}_00.md", "Week plan")
    ]

    for file_path, desc in plan_files:
        if Path(file_path).exists():
            plans.append(f"- {desc}: {file_path}")

    return '\n'.join(plans) if plans else "No planning files found"

def check_dependencies():
    """Check dependencies once per day"""
    last_check_file = '.last-dep-check'
    today_date = datetime.now().strftime('%Y-%m-%d')

    # Skip if already checked today or in CI environment
    if os.environ.get('SKIP_DEP_CHECK') == 'true':
        return

    try:
        if Path(last_check_file).exists():
            with open(last_check_file, 'r') as f:
                if f.read().strip() == today_date:
                    return
    except:
        pass

    print("üîç Checking for dependency updates (timeout in 10s)...")
    try:
        subprocess.run(['timeout', '10', 'bin/update-deps', '--quiet'],
                      check=False, capture_output=True)
    except:
        print("‚ö†Ô∏è  Dependency check timed out, continuing...")

    # Update check file
    with open(last_check_file, 'w') as f:
        f.write(today_date)
    print()

def run_sync(skip_sync=False):
    """Run data sync unless skipped"""
    if skip_sync:
        print("‚è≠Ô∏è  Skipping sync step")
        return

    print("üîÑ Syncing data sources...")
    subprocess.run(['bin/sync'], check=False)

def check_and_recover_database():
    """Check database and recover from Turso if needed"""
    db_path = '.data/today.db'
    db_missing = not Path(db_path).exists()
    tables_missing = False

    if not db_missing:
        # Check if critical tables exist
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name IN ('tasks', 'projects')")
            tables_exist = cursor.fetchone()[0]
            conn.close()
            if tables_exist != 2:
                tables_missing = True
                print("‚ö†Ô∏è  Database missing required tables")
        except:
            tables_missing = True
    else:
        print(f"‚ö†Ô∏è  Database not found at {db_path}")

    # Recover if needed
    if db_missing or tables_missing:
        print("üîÑ Database missing or incomplete - recovering from Turso...\n")

        # Create directory
        Path('.data').mkdir(exist_ok=True)

        # Create database with migrations if missing
        if db_missing:
            print("üî® Creating database and running migrations...")
            result = subprocess.run(['node', 'src/migrations.js'],
                                  capture_output=True, text=True)
            if result.returncode != 0:
                print(f"‚ùå Failed to create database: {result.stderr}")
                sys.exit(1)
            print("‚úÖ Database created with schema\n")

        # Pull data from Turso
        print("üì• Pulling data from Turso...")
        result = subprocess.run(['bin/turso-sync', 'pull'],
                              capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ Database recovered successfully\n")

            # Verify recovery
            if Path(db_path).exists():
                try:
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()
                    cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name IN ('tasks', 'projects')")
                    tables_exist = cursor.fetchone()[0]
                    conn.close()
                    if tables_exist != 2:
                        print("‚ùå Database recovery incomplete - tables still missing")
                        sys.exit(1)
                except Exception as e:
                    print(f"‚ùå Database verification failed: {e}")
                    sys.exit(1)
        else:
            print("‚ùå Failed to sync data from Turso")
            print("Please ensure TURSO_DATABASE_URL and TURSO_AUTH_TOKEN are set in .env")
            sys.exit(1)

    # Quick check that database has data
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Check sync log
        cursor.execute("SELECT MAX(created_at) FROM sync_log")
        last_sync = cursor.fetchone()[0]

        if last_sync:
            print(f"‚úÖ Database ready (last sync: {last_sync})\n")
        else:
            # Check task count
            cursor.execute("SELECT COUNT(*) FROM tasks")
            task_count = cursor.fetchone()[0]

            if task_count > 0:
                print(f"‚úÖ Database ready ({task_count} tasks found)\n")
            else:
                # Initialize sync log
                print("üìù Initializing sync log...")
                cursor.execute("""INSERT INTO sync_log
                    (timestamp, sync_type, success, source_system, target_system, created_at)
                    VALUES (datetime('now'), 'initial', 1, 'local', 'turso', datetime('now'))""")
                conn.commit()
                print("‚úÖ Database ready (initialized)\n")

        conn.close()
    except Exception as e:
        print(f"‚ùå Database check failed: {e}")
        sys.exit(1)

def lint_markdown():
    """Run markdown linting if available"""
    if Path('.markdownlint.json').exists():
        print("üìù Checking markdown formatting...")
        try:
            result = subprocess.run(
                ['npx', 'markdownlint-cli2', 'vault/plans/*.md'],
                capture_output=True, text=True, timeout=5
            )
            if result.stdout:
                # Show first 10 lines of output
                lines = result.stdout.strip().split('\n')[:10]
                for line in lines:
                    print(line)
        except:
            pass
        print()

def check_claude_auth():
    """Check if Claude CLI is authenticated"""
    print("üîê Checking Claude authentication...")
    result = subprocess.run(
        ['claude', '-p', 'Say "ok"'],
        capture_output=True,
        text=True
    )

    if any(err in result.stdout + result.stderr for err in ['Invalid API key', 'Please run /login', 'not authenticated']):
        print("\n‚ö†Ô∏è  Claude CLI is not authenticated!")
        print("‚îÅ" * 50)
        print("\nClaude is essential for daily reviews.")
        print("Please authenticate now by running:\n")
        print("  claude\n")
        print("Then follow the browser prompt to login.")
        print("After authentication, run 'bin/today' again.")
        print("‚îÅ" * 50)
        sys.exit(1)

    print("‚úÖ Claude is authenticated\n")

def update_review_file(dry_run=False):
    """Update the review file using Claude API to intelligently update the plan"""
    import anthropic
    import re
    import json
    from datetime import datetime
    import difflib

    # Get API key
    api_key = os.environ.get('TODAY_ANTHROPIC_KEY')
    if not api_key:
        print("‚ùå TODAY_ANTHROPIC_KEY not found in environment")
        print("Please ensure it's set in .env and encrypted with dotenvx")
        sys.exit(1)

    review_file = get_review_file_path()

    # Check if review file exists
    if not Path(review_file).exists():
        print(f"‚ùå Review file not found: {review_file}")
        print("Run 'bin/today' first to create today's review file")
        sys.exit(1)

    print(f"üìä Updating {review_file}...")
    if dry_run:
        print("üîç DRY RUN MODE - No changes will be made")

    # Get current database data
    try:
        result = subprocess.run(
            ['bin/db-query', 'daily'],
            capture_output=True,
            text=True,
            check=True
        )
        daily_data = result.stdout
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to query database: {e}")
        sys.exit(1)

    # Read current review file and create backup
    with open(review_file, 'r') as f:
        original_content = f.read()

    # Create a backup in memory
    backup_content = original_content
    original_lines = original_content.count('\n')

    # Get timezone from config
    timezone = 'America/New_York'  # default
    try:
        result = subprocess.run(['bin/get-config', 'timezone'],
                              capture_output=True, text=True)
        if result.returncode == 0 and result.stdout.strip():
            timezone = result.stdout.strip()
    except:
        pass

    # Get current time in configured timezone
    result = subprocess.run([f'TZ={timezone} date "+%I:%M %p"'],
                          shell=True, capture_output=True, text=True)
    current_time = result.stdout.strip()

    # Create prompt for Claude to return specific edits
    prompt = f"""You are updating a daily plan markdown file based on current database data.

CURRENT FILE HAS THESE KEY SECTIONS:
- Morning routine with tasks (some marked [x] with ‚úÖ 2025-09-22)
- Hip Mobility Workout with exercises
- Time blocks for the day
- An "Update" section showing status
- Reflection and Completed sections

CURRENT DATABASE DATA SUMMARY:
{daily_data[:1000]}... (truncated for analysis)

CURRENT TIME: {current_time} ET

RETURN A JSON OBJECT with these specific edits to make:
{{
  "update_section": "New content for the ### Update section (include the heading)",
  "tasks_to_check": ["exact text of tasks to mark as completed"],
  "numbers_to_update": [{{
    "find": "14 emails pending",
    "replace": "22 emails pending"
  }}]
}}

For the update_section, include:
### Update ({current_time})

- First bullet point about current status
- Second bullet about progress
- Third bullet about what's pending
- Optional fourth bullet

IMPORTANT:
- Only include tasks that should be newly checked off
- Don't include tasks already marked with [x]
- Be conservative - only update what you're certain about
- Keep the update section to 5-7 lines max"""

    # Call Claude API
    client = anthropic.Anthropic(api_key=api_key)

    try:
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=2000,
            temperature=0,
            messages=[{"role": "user", "content": prompt}]
        )

        response_text = response.content[0].text

        # Try to parse as JSON
        try:
            # Extract JSON if it's wrapped in markdown
            if '```json' in response_text:
                json_str = response_text.split('```json')[1].split('```')[0]
            elif '```' in response_text:
                json_str = response_text.split('```')[1].split('```')[0]
            elif '{' in response_text:
                # Find the JSON object in the response
                start = response_text.index('{')
                # Simple bracket counting to find the end
                count = 0
                end = start
                for i, char in enumerate(response_text[start:], start):
                    if char == '{':
                        count += 1
                    elif char == '}':
                        count -= 1
                        if count == 0:
                            end = i + 1
                            break
                json_str = response_text[start:end]
            else:
                json_str = response_text

            edits = json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Failed to parse Claude's response as JSON: {e}")
            print(f"Response: {response_text[:200]}...")
            sys.exit(1)

        # Apply edits to the content
        updated_content = original_content

        # 1. Update the Update section
        if 'update_section' in edits and edits['update_section']:
            update_pattern = r'### Update \([^)]+\)\n.*?(?=\n##|\n---|\Z)'
            if re.search(update_pattern, updated_content, re.DOTALL):
                updated_content = re.sub(update_pattern, edits['update_section'].rstrip(),
                                        updated_content, flags=re.DOTALL)
            else:
                # Add new update section after Reflection
                reflection_pattern = r'(## üí≠ Reflection\n\n\*[^*]+\*\n)'
                updated_content = re.sub(reflection_pattern,
                                        r'\1\n' + edits['update_section'] + '\n',
                                        updated_content)

        # 2. Check off completed tasks
        if 'tasks_to_check' in edits:
            for task in edits['tasks_to_check']:
                # Only check off if it's currently unchecked
                unchecked_pattern = f"- \\[ \\] {re.escape(task)}"
                if re.search(unchecked_pattern, updated_content):
                    updated_content = re.sub(unchecked_pattern,
                                            f"- [x] {task} ‚úÖ 2025-09-22",
                                            updated_content)

        # 3. Update numbers/counts
        if 'numbers_to_update' in edits:
            for update in edits['numbers_to_update']:
                if 'find' in update and 'replace' in update:
                    updated_content = updated_content.replace(update['find'], update['replace'])

        # SAFETY CHECKS
        updated_lines = updated_content.count('\n')
        if updated_lines < original_lines * 0.9:
            print(f"‚ö†Ô∏è  Safety check failed: Updated file has {updated_lines} lines vs original {original_lines}")
            print("Aborting update to prevent data loss")
            sys.exit(1)

        if len(updated_content) < len(original_content) * 0.9:
            print(f"‚ö†Ô∏è  Safety check failed: Updated content is too short")
            print(f"Original: {len(original_content)} chars, Updated: {len(updated_content)} chars")
            sys.exit(1)

        # Show what would be changed
        if dry_run:
            print("\nüìù Proposed changes:")
            print(f"Update section: {edits.get('update_section', 'No changes')[:200]}")
            print(f"Tasks to check: {edits.get('tasks_to_check', [])}")
            print(f"Numbers to update: {edits.get('numbers_to_update', [])}")
            print("\n‚úÖ Dry run complete - no changes made")
        else:
            # Write updated content back to file
            with open(review_file, 'w') as f:
                f.write(updated_content)
            print(f"‚úÖ Updated {review_file}")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        if not dry_run:
            print("Restoring original content...")
            with open(review_file, 'w') as f:
                f.write(backup_content)
        sys.exit(1)

def create_review_from_template():
    """Create daily review file from template if it doesn't exist"""
    review_file = get_review_file_path()

    if Path(review_file).exists():
        return review_file

    template_file = "vault/templates/daily-plan.md"
    if not Path(template_file).exists():
        return review_file

    print(f"üìù Creating daily plan from template...")

    # Ensure directory exists
    Path(review_file).parent.mkdir(parents=True, exist_ok=True)

    # Read template
    with open(template_file, 'r') as f:
        content = f.read()

    # Replace template variables
    now = datetime.now()
    stage_theme, stage_focus = get_stage_info()

    replacements = {
        '{{DAY_OF_WEEK}}': now.strftime('%A'),
        '{{MONTH_NAME}}': now.strftime('%B'),
        '{{DAY}}': str(now.day),
        '{{YEAR}}': str(now.year),
        '{{FULL_DATE}}': now.strftime('%B %d, %Y'),
        '{{STAGE_THEME}}': stage_theme,
        '{{STAGE_FOCUS}}': stage_focus,
        '{{PRIORITIES_FROM_DATABASE}}': '',
        '{{MORNING_TIME_BLOCKS}}': '',
        '{{AFTERNOON_TIME_BLOCKS}}': '',
        '{{EVENING_TIME_BLOCKS}}': '',
    }

    for key, value in replacements.items():
        content = content.replace(key, value)

    # Write the new review file
    with open(review_file, 'w') as f:
        f.write(content)

    print(f"‚úÖ Created daily plan: {review_file}\n")
    return review_file

def run_interactive_session(direct_request=None, non_interactive=False):
    """Run the interactive Claude session"""
    review_file = get_review_file_path()
    stage_theme, stage_focus = get_stage_info()

    # Get timezone from config
    timezone = 'America/New_York'  # default
    try:
        result = subprocess.run(['bin/get-config', 'timezone'],
                              capture_output=True, text=True)
        if result.returncode == 0 and result.stdout.strip():
            timezone = result.stdout.strip()
    except:
        pass

    # Build the context with proper timezone
    result = subprocess.run([f'TZ={timezone} date "+%A, %B %d, %Y at %I:%M %p %Z"'],
                          shell=True, capture_output=True, text=True)
    current_time = result.stdout.strip()

    result = subprocess.run([f'TZ={timezone} date "+%Y-%m-%d"'],
                          shell=True, capture_output=True, text=True)
    current_date = result.stdout.strip()

    result = subprocess.run([f'TZ={timezone} date "+%A"'],
                          shell=True, capture_output=True, text=True)
    day_of_week = result.stdout.strip()

    # Get task counts from markdown
    task_stats = get_task_statistics()
    task_count = str(task_stats['total'])
    overdue_count = str(task_stats['overdue'])
    high_priority_count = str(task_stats['high_priority'])

    # Get health metrics
    health_metrics = get_health_metrics()

    # Get existing plans
    existing_plans = get_existing_plans()

    # Read TODAY.md for context - always include this, even for direct requests
    today_context = ""
    if Path('TODAY.md').exists():
        with open('TODAY.md', 'r') as f:
            today_content = f.read()
            # Remove the critical first steps section
            today_content = re.sub(r'### üî¥ CRITICAL FIRST STEPS üî¥.*?(?=##|$)', '',
                                  today_content, flags=re.DOTALL)
            # Get the session instructions part
            match = re.search(r'## Session Instructions for Claude.*', today_content, re.DOTALL)
            if match:
                today_context = match.group(0)

    # Build the common context that all sessions need
    common_context = f"""## Pre-Computed Context
- **Current Time**: {current_time}
- **Date**: {current_date} ({day_of_week})
- **Stage**: {stage_theme} - {stage_focus}
- **Review File**: {review_file}
- **Active Tasks**: {task_count} (Overdue: {overdue_count}, High Priority: {high_priority_count})
{health_metrics}

## Existing Plans
{existing_plans}

## Database Tables Available:
- markdown_tasks: Current tasks stored directly from markdown files
- emails: Recent emails with subjects, senders, reply status
- calendar_events: Upcoming events with times, locations
- contacts: Contact information
- file_tracking: Recently modified files
- people_to_contact: People needing follow-up
- diary: Day One journal entries with text, dates, locations

## Available Commands
- bin/db-query daily - Get comprehensive daily review data
- bin/db-query tasks - Get priority tasks
- bin/mark-done 'task' - Mark a task as complete
- bin/progress 'note' - Add a progress note

{today_context}"""

    if direct_request:
        if non_interactive:
            print("ü§ñ Running Claude in non-interactive mode...")
            prompt = f"""# Focused Work Session - NON-INTERACTIVE MODE

## CRITICAL: You are in NON-INTERACTIVE mode
- You have FULL PERMISSION to create, update, and modify files
- Do NOT ask for permission - execute the requested actions immediately
- The user ran this command specifically requesting: "{direct_request}"
- Complete the task WITHOUT asking for confirmation

{common_context}

## Direct Request from User
"{direct_request}"

Execute the request NOW without asking for permission!"""

            subprocess.run(['claude', '--print', '--dangerously-skip-permissions', prompt])
        else:
            print(f"üìä Starting focused session: {direct_request}\n")
            print("ü§ñ Starting Claude focused session...")

            prompt = f"""# Focused Work Session

{common_context}

## User Request
"{direct_request}"

Please help me with this specific request."""

            subprocess.run(['claude', prompt])
    else:
        print("ü§ñ Starting Claude daily review session...")
        prompt = f"""# Daily Review Session

{common_context}

Please help me with my daily review."""

        subprocess.run(['claude', prompt])

    # Session end summary
    print("\n" + "‚îÅ" * 50)
    print("‚úÖ Claude session ended\n")
    print(f"üìù Your review should be in: {review_file}\n")
    print("üí° Continue tracking progress with:")
    print("   bin/mark-done 'task description'")
    print("   bin/progress 'note'")
    print("‚îÅ" * 50 + "\n")

def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description='Today - Daily review and planning tool')
    parser.add_argument('command', nargs='?', help='Command to run (e.g., "update")')
    parser.add_argument('request', nargs='*', help='Direct request for Claude')
    parser.add_argument('--no-sync', action='store_true', help='Skip the sync step')
    parser.add_argument('--non-interactive', action='store_true', help='Run in non-interactive mode')

    args = parser.parse_args()

    # Load environment variables
    load_dotenv()

    # Check dependencies once per day (unless in non-interactive mode)
    if not args.non_interactive:
        check_dependencies()

    # Handle update command
    if args.command == 'update':
        print("üìä Running automated review update...")
        if not args.no_sync:
            run_sync()
        update_review_file(dry_run=False)
        return

    # Handle dry-run command
    if args.command == 'dry-run':
        print("üìä Running review update in dry-run mode...")
        if not args.no_sync:
            run_sync()
        update_review_file(dry_run=True)
        return

    # Join any remaining arguments as the direct request
    direct_request = None
    if args.command and args.command != 'update':
        # The first positional arg is actually a request, not a command
        parts = [args.command] + args.request
        direct_request = ' '.join(parts)
    elif args.request:
        direct_request = ' '.join(args.request)

    # Display appropriate message
    if direct_request:
        print(f"üìä Starting focused session: {direct_request}")
    else:
        print("üìä Starting daily review process...")

    # Check Claude authentication (unless non-interactive)
    if not args.non_interactive:
        check_claude_auth()

    # Run sync (unless skipped)
    if not args.no_sync:
        run_sync(skip_sync=False)
    else:
        print("‚ö†Ô∏è  Skipping sync (--no-sync flag provided)")

    # Check and recover database if needed
    check_and_recover_database()

    # Run markdown linting (non-blocking)
    if not args.non_interactive:
        lint_markdown()

    # Create review file from template if needed
    create_review_from_template()

    # Run the appropriate session
    run_interactive_session(direct_request, args.non_interactive)

if __name__ == '__main__':
    main()